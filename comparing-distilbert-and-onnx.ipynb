{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":303163,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":258833,"modelId":280029}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install  onnxruntime","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-26T14:39:32.612945Z","iopub.execute_input":"2025-03-26T14:39:32.613281Z","iopub.status.idle":"2025-03-26T14:39:39.900945Z","shell.execute_reply.started":"2025-03-26T14:39:32.613252Z","shell.execute_reply":"2025-03-26T14:39:39.899884Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting onnxruntime\n  Downloading onnxruntime-1.21.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\nCollecting coloredlogs (from onnxruntime)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.3.25)\nRequirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.26.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.2)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.6->onnxruntime) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.6->onnxruntime) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.6->onnxruntime) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.6->onnxruntime) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.6->onnxruntime) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.6->onnxruntime) (2.4.1)\nCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21.6->onnxruntime) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21.6->onnxruntime) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.6->onnxruntime) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.21.6->onnxruntime) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.21.6->onnxruntime) (2024.2.0)\nDownloading onnxruntime-1.21.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\nSuccessfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.21.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import onnxruntime as ort\nimport numpy as np\nfrom transformers import DistilBertTokenizer,DistilBertForSequenceClassification\nimport torch\nimport time","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T15:00:42.323667Z","iopub.execute_input":"2025-03-26T15:00:42.324019Z","iopub.status.idle":"2025-03-26T15:00:42.328239Z","shell.execute_reply.started":"2025-03-26T15:00:42.323989Z","shell.execute_reply":"2025-03-26T15:00:42.327311Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"distil_model = DistilBertForSequenceClassification.from_pretrained(\n    \"ashish-001/DistilBert-Amazon-review-sentiment-classifier\")\ndistil_tokenizer = DistilBertTokenizer.from_pretrained(\n    \"ashish-001/DistilBert-Amazon-review-sentiment-classifier\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T14:41:06.901966Z","iopub.execute_input":"2025-03-26T14:41:06.902631Z","iopub.status.idle":"2025-03-26T14:41:13.761988Z","shell.execute_reply.started":"2025-03-26T14:41:06.902593Z","shell.execute_reply":"2025-03-26T14:41:13.761002Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edb2c9e759414cc2b794735ed608b63f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"632fd7aba12f45d6a6c005009347f991"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.25k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a94ca5851e542cf920aeb13c4c917d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1c77b3d52b84b50adedba29ec445f7f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88df4f8e19834bc2bbed87448bc5bbbc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6257a43f54b14ba58d4804fe35ccdd6d"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"session = ort.InferenceSession(\"/kaggle/input/distilbert_onnc_quantized_for_amazon_review/onnx/default/1/distilbertmodel_quantized.onnx\", providers=[\"CPUExecutionProvider\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T14:44:59.823170Z","iopub.execute_input":"2025-03-26T14:44:59.823604Z","iopub.status.idle":"2025-03-26T14:45:01.152204Z","shell.execute_reply.started":"2025-03-26T14:44:59.823571Z","shell.execute_reply":"2025-03-26T14:45:01.151256Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"text=distil_tokenizer(\"hello\",return_tensors='np')\ninput_names = [inp.name for inp in session.get_inputs()]\nonnx_inputs = {name: text[name] for name in text}\noutputs = session.run(None, onnx_inputs)\nprob=torch.nn.functional.sigmoid(logits)\nind=np.argmax([probs[0][0].item(),probs[0][1].item()])\nprint(\"Positive\" if ind else  \"Negative\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"t=distil_tokenizer(\"This is a  good product\",max_length=256,\n        truncation=True,\n        padding=\"max_length\",\n        return_tensors=\"pt\")\noutput = distil_model(**t)\nlogits = output.logits\nprobs = torch.nn.functional.sigmoid(logits)\nind=np.argmax([probs[0][0].item(),probs[0][1].item()])\nprint(\"Positive\" if ind else  \"Negative\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T14:52:30.622639Z","iopub.execute_input":"2025-03-26T14:52:30.623000Z","iopub.status.idle":"2025-03-26T14:52:30.855493Z","shell.execute_reply.started":"2025-03-26T14:52:30.622969Z","shell.execute_reply":"2025-03-26T14:52:30.854450Z"}},"outputs":[{"name":"stdout","text":"tensor([[0.2150, 0.8316]], grad_fn=<SigmoidBackward0>)\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"text_input = \"This is a good product\"\n\n\nnum_runs = 10 \n\n\nonnx_times = []\nfor _ in range(num_runs):\n    start_time = time.time()\n    text = distil_tokenizer(text_input, return_tensors=\"np\")\n    input_names = [inp.name for inp in session.get_inputs()]\n    onnx_inputs = {name: text[name] for name in text}\n    outputs = session.run(None, onnx_inputs)\n    logits = torch.tensor(outputs[0])  \n    probs = torch.nn.functional.sigmoid(logits)\n    onnx_times.append(time.time() - start_time)\n\nonnx_avg_time = sum(onnx_times) / num_runs\nprint(f\"ONNX Average Inference Time: {onnx_avg_time:.6f} sec\")\n\n\npytorch_times = []\nfor _ in range(num_runs):\n    start_time = time.time()\n    t = distil_tokenizer(\n        text_input,\n        max_length=256,\n        truncation=True,\n        padding=\"max_length\",\n        return_tensors=\"pt\"\n    )\n    output = distil_model(**t)\n    logits = output.logits\n    probs = torch.nn.functional.sigmoid(logits)\n    pytorch_times.append(time.time() - start_time)\n\npytorch_avg_time = sum(pytorch_times) / num_runs\nprint(f\"PyTorch Average Inference Time: {pytorch_avg_time:.6f} sec\")\n\n\nspeedup = (pytorch_avg_time - onnx_avg_time) / pytorch_avg_time * 100\nprint(f\"ONNX is {speedup:.2f}% faster than PyTorch\" if speedup > 0 else f\"PyTorch is {-speedup:.2f}% faster than ONNX\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T15:02:44.494743Z","iopub.execute_input":"2025-03-26T15:02:44.495120Z","iopub.status.idle":"2025-03-26T15:02:46.733232Z","shell.execute_reply.started":"2025-03-26T15:02:44.495092Z","shell.execute_reply":"2025-03-26T15:02:46.732162Z"}},"outputs":[{"name":"stdout","text":"ONNX Average Inference Time: 0.007902 sec\nPyTorch Average Inference Time: 0.214982 sec\nONNX is 96.32% faster than PyTorch\n","output_type":"stream"}],"execution_count":27}]}